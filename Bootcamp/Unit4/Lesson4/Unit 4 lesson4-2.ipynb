{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook referes to unit 4 lesson 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 0:\n",
    "- try SVM \n",
    "- feature engineer \n",
    "- get score >= 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice[:int(len(alice)/10)])\n",
    "persuasion = text_cleaner(persuasion[:int(len(persuasion)/10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                                      (Oh, dear, !)  Carroll"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commander</th>\n",
       "      <th>powerful</th>\n",
       "      <th>rapid</th>\n",
       "      <th>Baldwin</th>\n",
       "      <th>rent</th>\n",
       "      <th>creep</th>\n",
       "      <th>pop</th>\n",
       "      <th>sure</th>\n",
       "      <th>principal</th>\n",
       "      <th>unsolicitous</th>\n",
       "      <th>...</th>\n",
       "      <th>fountain</th>\n",
       "      <th>known</th>\n",
       "      <th>finish</th>\n",
       "      <th>genteel</th>\n",
       "      <th>fool</th>\n",
       "      <th>spirit</th>\n",
       "      <th>expedition</th>\n",
       "      <th>intention</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  commander powerful rapid Baldwin rent creep pop sure principal unsolicitous  \\\n",
       "0         0        0     0       0    0     0   0    0         0            0   \n",
       "1         0        0     0       0    0     0   0    0         0            0   \n",
       "2         0        0     0       0    0     0   0    0         0            0   \n",
       "3         0        0     0       0    0     0   0    0         0            0   \n",
       "4         0        0     0       0    0     0   0    0         0            0   \n",
       "\n",
       "   ... fountain known finish genteel fool spirit expedition intention  \\\n",
       "0  ...        0     0      0       0    0      0          0         0   \n",
       "1  ...        0     0      0       0    0      0          0         0   \n",
       "2  ...        0     0      0       0    0      0          0         0   \n",
       "3  ...        0     0      0       0    0      0          0         0   \n",
       "4  ...        0     0      0       0    0      0          0         0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
       "1  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "3                                      (Oh, dear, !)     Carroll  \n",
       "4                                      (Oh, dear, !)     Carroll  \n",
       "\n",
       "[5 rows x 1614 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commander</th>\n",
       "      <th>powerful</th>\n",
       "      <th>rapid</th>\n",
       "      <th>Baldwin</th>\n",
       "      <th>rent</th>\n",
       "      <th>creep</th>\n",
       "      <th>pop</th>\n",
       "      <th>sure</th>\n",
       "      <th>principal</th>\n",
       "      <th>unsolicitous</th>\n",
       "      <th>...</th>\n",
       "      <th>known</th>\n",
       "      <th>finish</th>\n",
       "      <th>genteel</th>\n",
       "      <th>fool</th>\n",
       "      <th>spirit</th>\n",
       "      <th>expedition</th>\n",
       "      <th>intention</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>67</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>63</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>30</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>3</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>3</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1615 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  commander powerful rapid Baldwin rent creep pop sure principal unsolicitous  \\\n",
       "0         0        0     0       0    0     0   0    0         0            0   \n",
       "1         0        0     0       0    0     0   0    0         0            0   \n",
       "2         0        0     0       0    0     0   0    0         0            0   \n",
       "3         0        0     0       0    0     0   0    0         0            0   \n",
       "4         0        0     0       0    0     0   0    0         0            0   \n",
       "\n",
       "   ... known finish genteel fool spirit expedition intention  \\\n",
       "0  ...     0      0       0    0      0          0         0   \n",
       "1  ...     0      0       0    0      0          0         0   \n",
       "2  ...     0      0       0    0      0          0         0   \n",
       "3  ...     0      0       0    0      0          0         0   \n",
       "4  ...     0      0       0    0      0          0         0   \n",
       "\n",
       "                                       text_sentence sentence_length  \\\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...              67   \n",
       "1  (So, she, was, considering, in, her, own, mind...              63   \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...              30   \n",
       "3                                      (Oh, dear, !)               3   \n",
       "4                                      (Oh, dear, !)               3   \n",
       "\n",
       "  text_source  \n",
       "0     Carroll  \n",
       "1     Carroll  \n",
       "2     Carroll  \n",
       "3     Carroll  \n",
       "4     Carroll  \n",
       "\n",
       "[5 rows x 1615 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the sentence length\n",
    "length = []\n",
    "for i in range(len(sentences)):\n",
    "    length.append(len(sentences[0].iloc[i]))\n",
    "\n",
    "# add the length as a feature to df at position 1 before the end\n",
    "word_counts.insert(len(word_counts.columns) -1, 'sentence_length', length)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define lists\n",
    "alpha_list, adj_list, adv_list, aux_list, conj_list = [], [], [], [], []\n",
    "det_list, noun_list, num_list, part_list, pron_list, verb_list = [], [], [], [], [], []\n",
    "\n",
    "# count each the values from each and add to correct list\n",
    "for i in range(len(sentences)):\n",
    "    # get eacj sentence\n",
    "    doc = sentences[0].iloc[i]\n",
    "    \n",
    "    # define variables\n",
    "    alpha_cnt, adj_cnt, adv_cnt, aux_cnt, conj_cnt, det_cnt = 0, 0, 0, 0, 0, 0\n",
    "    noun_cnt, num_cnt, part_cnt, pron_cnt, verb_cnt = 0, 0, 0, 0, 0\n",
    "    \n",
    "    # check each work in the sentence\n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            alpha_cnt += 1\n",
    "        if token.pos_ == 'ADJ':\n",
    "            adj_cnt += 1\n",
    "        if token.pos_ == 'ADV':\n",
    "            adv_cnt += 1\n",
    "        if token.pos_ == 'AUX':\n",
    "            aux_cnt += 1\n",
    "        if token.pos_ == 'CONJ':\n",
    "            conj_cnt += 1\n",
    "        if token.pos_ == 'DET':\n",
    "            det_cnt += 1\n",
    "        if token.pos_ == 'NOUN':\n",
    "            noun_cnt += 1\n",
    "        if token.pos_ == 'NUM':\n",
    "            num_cnt += 1\n",
    "        if token.pos_ == 'PART':\n",
    "            part_cnt += 1\n",
    "        if token.pos_ == 'PRON':\n",
    "            pron_cnt += 1\n",
    "        if token.pos_ == 'VERB':\n",
    "            verb_cnt += 1\n",
    "            \n",
    "    # add values to lists        \n",
    "    alpha_list.append(alpha_cnt)\n",
    "    adj_list.append(adj_cnt)\n",
    "    adv_list.append(adv_cnt)\n",
    "    aux_list.append(aux_cnt)\n",
    "    conj_list.append(conj_cnt)\n",
    "    det_list.append(det_cnt)\n",
    "    noun_list.append(noun_cnt)\n",
    "    num_list.append(num_cnt)\n",
    "    part_list.append(part_cnt)\n",
    "    pron_list.append(pron_cnt)\n",
    "    verb_list.append(verb_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commander</th>\n",
       "      <th>powerful</th>\n",
       "      <th>rapid</th>\n",
       "      <th>Baldwin</th>\n",
       "      <th>rent</th>\n",
       "      <th>creep</th>\n",
       "      <th>pop</th>\n",
       "      <th>sure</th>\n",
       "      <th>principal</th>\n",
       "      <th>unsolicitous</th>\n",
       "      <th>...</th>\n",
       "      <th>conj_cnt</th>\n",
       "      <th>det_cnt</th>\n",
       "      <th>noun_cnt</th>\n",
       "      <th>num_cnt</th>\n",
       "      <th>part_cnt</th>\n",
       "      <th>pron_cnt</th>\n",
       "      <th>verb_cnt</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>67</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>63</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>30</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>3</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>3</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  commander powerful rapid Baldwin rent creep pop sure principal unsolicitous  \\\n",
       "0         0        0     0       0    0     0   0    0         0            0   \n",
       "1         0        0     0       0    0     0   0    0         0            0   \n",
       "2         0        0     0       0    0     0   0    0         0            0   \n",
       "3         0        0     0       0    0     0   0    0         0            0   \n",
       "4         0        0     0       0    0     0   0    0         0            0   \n",
       "\n",
       "   ... conj_cnt det_cnt noun_cnt num_cnt part_cnt pron_cnt verb_cnt  \\\n",
       "0  ...        0       7       11       0        2        4       13   \n",
       "1  ...        0       7        8       0        1        4       11   \n",
       "2  ...        0       3        2       0        1        2        5   \n",
       "3  ...        0       0        0       0        0        0        0   \n",
       "4  ...        0       0        0       0        0        0        0   \n",
       "\n",
       "                                       text_sentence sentence_length  \\\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...              67   \n",
       "1  (So, she, was, considering, in, her, own, mind...              63   \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...              30   \n",
       "3                                      (Oh, dear, !)               3   \n",
       "4                                      (Oh, dear, !)               3   \n",
       "\n",
       "  text_source  \n",
       "0     Carroll  \n",
       "1     Carroll  \n",
       "2     Carroll  \n",
       "3     Carroll  \n",
       "4     Carroll  \n",
       "\n",
       "[5 rows x 1626 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new features to df\n",
    "word_counts.insert(len(word_counts.columns) -3, 'alpha_cnt', alpha_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'adj_cnt', adj_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'adv_cnt', adv_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'aux_cnt', aux_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'conj_cnt', conj_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'det_cnt', det_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'noun_cnt', noun_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'num_cnt', num_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'part_cnt', part_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'pron_cnt', pron_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'verb_cnt', verb_list)\n",
    "\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 1624) (266,)\n",
      "Training set score: 0.981203007518797\n",
      "\n",
      "Test set score: 0.8707865168539326\n"
     ]
    }
   ],
   "source": [
    "y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=0)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200) \n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9774436090225563\n",
      "\n",
      "Test set score: 0.8651685393258427\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "clf = svm.SVC(gamma='scale', kernel='linear', probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9172932330827067\n",
      "\n",
      "Test set score: 0.848314606741573\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(penalty='elasticnet', loss='log')\n",
    "sgd.fit(X_train, y_train)\n",
    "print('Training set score:', sgd.score(X_train, y_train))\n",
    "print('\\nTest set score:', sgd.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.19280839, 1.12901998, 1.2097621 , 1.13896251, 1.15816426]),\n",
       " 'score_time': array([0.036901  , 0.03386927, 0.03291416, 0.04287744, 0.02692771]),\n",
       " 'test_score': array([0.80898876, 0.83146067, 0.87640449, 0.80898876, 0.73863636])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross valuate for SVM\n",
    "cv_results = cross_validate(clf, X, y, cv=5)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88888889, 0.84444444, 0.88888889, 0.82222222, 0.91111111,\n",
       "       0.84090909, 0.81818182, 0.65909091, 0.79545455, 0.86046512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "cv_results = cross_validate(nb, X, y, cv=10)\n",
    "cv_results['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1:\n",
    "copmare Alice vs other book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "# print list of options\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Moby Dick by Herman Melville 1851]\\r\\n\\r\\n\\r\\nETYMOLOGY.\\r\\n\\r\\n(Supplied by a Late Consumptive Usher to a Grammar'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "moby = gutenberg.raw('melville-moby_dick.txt')\n",
    "\n",
    "# print first few char\n",
    "moby[:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ETYMOLOGY. (Supplied by a Late Consumptive Usher to a Grammar School) The pale Usher threadbare in coat, heart, body, and brain; I see him now. He was ever dusting his old lexicons and grammars, with '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean keep 1/60 of the length\n",
    "moby = text_cleaner(moby[:int(len(moby)/60)])\n",
    "moby[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4344"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the cleaned novel\n",
    "moby_doc = nlp(moby)\n",
    "len(moby_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>(\")</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>(It, was, not, till, the, boats, returned, fro...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>(\", NEWSPAPER, ACCOUNT, OF, THE, TAKING, AND, ...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>(\")</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>(It, is, generally, well, known, that, out, of...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0         1\n",
       "541                                                (\")  Melville\n",
       "542  (It, was, not, till, the, boats, returned, fro...  Melville\n",
       "543  (\", NEWSPAPER, ACCOUNT, OF, THE, TAKING, AND, ...  Melville\n",
       "544                                                (\")  Melville\n",
       "545  (It, is, generally, well, known, that, out, of...  Melville"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NEW df with Alice and Moby Dick.\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "moby_sents = [[sent, \"Melville\"] for sent in moby_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + moby_sents)\n",
    "sentences.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n",
      "Processing row 450\n",
      "Processing row 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soever</th>\n",
       "      <th>indirectly</th>\n",
       "      <th>creep</th>\n",
       "      <th>pop</th>\n",
       "      <th>COMMODORE</th>\n",
       "      <th>sure</th>\n",
       "      <th>bone</th>\n",
       "      <th>ALICE</th>\n",
       "      <th>PROFANE</th>\n",
       "      <th>little</th>\n",
       "      <th>...</th>\n",
       "      <th>milk</th>\n",
       "      <th>shine</th>\n",
       "      <th>restless</th>\n",
       "      <th>vent</th>\n",
       "      <th>eat</th>\n",
       "      <th>fountain</th>\n",
       "      <th>UNO</th>\n",
       "      <th>finish</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1440 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  soever indirectly creep pop COMMODORE sure bone ALICE PROFANE little  ...  \\\n",
       "0      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "1      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "2      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "3      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "4      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "\n",
       "  milk shine restless vent eat fountain UNO finish  \\\n",
       "0    0     0        0    0   0        0   0      0   \n",
       "1    0     0        0    0   0        0   0      0   \n",
       "2    0     0        0    0   0        0   0      0   \n",
       "3    0     0        0    0   0        0   0      0   \n",
       "4    0     0        0    0   0        0   0      0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
       "1  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "3                                      (Oh, dear, !)     Carroll  \n",
       "4                                      (Oh, dear, !)     Carroll  \n",
       "\n",
       "[5 rows x 1440 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "mobywords = bag_of_words(moby_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + mobywords)\n",
    "\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soever</th>\n",
       "      <th>indirectly</th>\n",
       "      <th>creep</th>\n",
       "      <th>pop</th>\n",
       "      <th>COMMODORE</th>\n",
       "      <th>sure</th>\n",
       "      <th>bone</th>\n",
       "      <th>ALICE</th>\n",
       "      <th>PROFANE</th>\n",
       "      <th>little</th>\n",
       "      <th>...</th>\n",
       "      <th>shine</th>\n",
       "      <th>restless</th>\n",
       "      <th>vent</th>\n",
       "      <th>eat</th>\n",
       "      <th>fountain</th>\n",
       "      <th>UNO</th>\n",
       "      <th>finish</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(\")</td>\n",
       "      <td>1</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(It, was, not, till, the, boats, returned, fro...</td>\n",
       "      <td>31</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(\", NEWSPAPER, ACCOUNT, OF, THE, TAKING, AND, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(\")</td>\n",
       "      <td>1</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(It, is, generally, well, known, that, out, of...</td>\n",
       "      <td>26</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1441 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    soever indirectly creep pop COMMODORE sure bone ALICE PROFANE little  ...  \\\n",
       "541      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "542      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "543      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "544      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "545      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "\n",
       "    shine restless vent eat fountain UNO finish  \\\n",
       "541     0        0    0   0        0   0      0   \n",
       "542     0        0    0   0        0   0      0   \n",
       "543     0        0    0   0        0   0      0   \n",
       "544     0        0    0   0        0   0      0   \n",
       "545     0        0    0   0        0   0      0   \n",
       "\n",
       "                                         text_sentence sentence_length  \\\n",
       "541                                                (\")               1   \n",
       "542  (It, was, not, till, the, boats, returned, fro...              31   \n",
       "543  (\", NEWSPAPER, ACCOUNT, OF, THE, TAKING, AND, ...              15   \n",
       "544                                                (\")               1   \n",
       "545  (It, is, generally, well, known, that, out, of...              26   \n",
       "\n",
       "    text_source  \n",
       "541    Melville  \n",
       "542    Melville  \n",
       "543    Melville  \n",
       "544    Melville  \n",
       "545    Melville  \n",
       "\n",
       "[5 rows x 1441 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the sentence length\n",
    "length = []\n",
    "for i in range(len(sentences)):\n",
    "    length.append(len(sentences[0].iloc[i]))\n",
    "\n",
    "# add the length as a feature to df at position 1 before the end\n",
    "word_counts.insert(len(word_counts.columns) -1, 'sentence_length', length)\n",
    "word_counts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists\n",
    "alpha_list, adj_list, adv_list, aux_list, conj_list = [], [], [], [], []\n",
    "det_list, noun_list, num_list, part_list, pron_list, verb_list = [], [], [], [], [], []\n",
    "\n",
    "# count each the values from each and add to correct list\n",
    "for i in range(len(sentences)):\n",
    "    # get eacj sentence\n",
    "    doc = sentences[0].iloc[i]\n",
    "    \n",
    "    # define variables\n",
    "    alpha_cnt, adj_cnt, adv_cnt, aux_cnt, conj_cnt, det_cnt = 0, 0, 0, 0, 0, 0\n",
    "    noun_cnt, num_cnt, part_cnt, pron_cnt, verb_cnt = 0, 0, 0, 0, 0\n",
    "    \n",
    "    # check each work in the sentence\n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            alpha_cnt += 1\n",
    "        if token.pos_ == 'ADJ':\n",
    "            adj_cnt += 1\n",
    "        if token.pos_ == 'ADV':\n",
    "            adv_cnt += 1\n",
    "        if token.pos_ == 'AUX':\n",
    "            aux_cnt += 1\n",
    "        if token.pos_ == 'CONJ':\n",
    "            conj_cnt += 1\n",
    "        if token.pos_ == 'DET':\n",
    "            det_cnt += 1\n",
    "        if token.pos_ == 'NOUN':\n",
    "            noun_cnt += 1\n",
    "        if token.pos_ == 'NUM':\n",
    "            num_cnt += 1\n",
    "        if token.pos_ == 'PART':\n",
    "            part_cnt += 1\n",
    "        if token.pos_ == 'PRON':\n",
    "            pron_cnt += 1\n",
    "        if token.pos_ == 'VERB':\n",
    "            verb_cnt += 1\n",
    "            \n",
    "    # add values to lists        \n",
    "    alpha_list.append(alpha_cnt)\n",
    "    adj_list.append(adj_cnt)\n",
    "    adv_list.append(adv_cnt)\n",
    "    aux_list.append(aux_cnt)\n",
    "    conj_list.append(conj_cnt)\n",
    "    det_list.append(det_cnt)\n",
    "    noun_list.append(noun_cnt)\n",
    "    num_list.append(num_cnt)\n",
    "    part_list.append(part_cnt)\n",
    "    pron_list.append(pron_cnt)\n",
    "    verb_list.append(verb_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soever</th>\n",
       "      <th>indirectly</th>\n",
       "      <th>creep</th>\n",
       "      <th>pop</th>\n",
       "      <th>COMMODORE</th>\n",
       "      <th>sure</th>\n",
       "      <th>bone</th>\n",
       "      <th>ALICE</th>\n",
       "      <th>PROFANE</th>\n",
       "      <th>little</th>\n",
       "      <th>...</th>\n",
       "      <th>conj_cnt</th>\n",
       "      <th>det_cnt</th>\n",
       "      <th>noun_cnt</th>\n",
       "      <th>num_cnt</th>\n",
       "      <th>part_cnt</th>\n",
       "      <th>pron_cnt</th>\n",
       "      <th>verb_cnt</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>67</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>63</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>30</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>3</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>3</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1452 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  soever indirectly creep pop COMMODORE sure bone ALICE PROFANE little  ...  \\\n",
       "0      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "1      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "2      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "3      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "4      0          0     0   0         0    0    0     0       0      0  ...   \n",
       "\n",
       "  conj_cnt det_cnt noun_cnt num_cnt part_cnt pron_cnt verb_cnt  \\\n",
       "0        0       7       11       0        2        4       13   \n",
       "1        0       7        8       0        1        4       11   \n",
       "2        0       3        2       0        1        2        5   \n",
       "3        0       0        0       0        0        0        0   \n",
       "4        0       0        0       0        0        0        0   \n",
       "\n",
       "                                       text_sentence sentence_length  \\\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...              67   \n",
       "1  (So, she, was, considering, in, her, own, mind...              63   \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...              30   \n",
       "3                                      (Oh, dear, !)               3   \n",
       "4                                      (Oh, dear, !)               3   \n",
       "\n",
       "  text_source  \n",
       "0     Carroll  \n",
       "1     Carroll  \n",
       "2     Carroll  \n",
       "3     Carroll  \n",
       "4     Carroll  \n",
       "\n",
       "[5 rows x 1452 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new features to df\n",
    "word_counts.insert(len(word_counts.columns) -3, 'alpha_cnt', alpha_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'adj_cnt', adj_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'adv_cnt', adv_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'aux_cnt', aux_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'conj_cnt', conj_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'det_cnt', det_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'noun_cnt', noun_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'num_cnt', num_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'part_cnt', part_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'pron_cnt', pron_list)\n",
    "word_counts.insert(len(word_counts.columns) -3, 'verb_cnt', verb_list)\n",
    "\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327, 1450) (327,)\n",
      "Training set score: 0.9571865443425076\n",
      "\n",
      "Test set score: 0.9315068493150684\n"
     ]
    }
   ],
   "source": [
    "y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200) \n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Carroll</th>\n",
       "      <th>Melville</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melville</th>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        Carroll  Melville\n",
       "text_source                   \n",
       "Carroll           33        10\n",
       "Melville           5       171"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = lr.predict(X_test)\n",
    "pd.crosstab(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
